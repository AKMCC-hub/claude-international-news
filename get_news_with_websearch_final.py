#!/usr/bin/env python3
"""
ä½¿ç”¨ web_search å·¥å…·è·å–æœ€æ–°å›½é™…æ–°é—»
æ”¯æŒ Brotli è§£å‹ç¼©
"""

import requests
import json
from datetime import datetime

# å¯¼å…¥é…ç½®æ¨¡å—
try:
    from config import API_KEY, API_BASE_URL, DEFAULT_MODEL
except ImportError:
    # å¦‚æœé…ç½®æ¨¡å—ä¸å­˜åœ¨ï¼Œä»ç¯å¢ƒå˜é‡è·å–
    import os
    API_KEY = os.environ.get('API_KEY')
    if not API_KEY:
        raise ValueError("API_KEY not found. Please set it in environment variable or .env file")
    API_BASE_URL = os.environ.get('API_BASE_URL', "https://spai.aicoding.sh")
    DEFAULT_MODEL = os.environ.get('DEFAULT_MODEL', "claude-sonnet-4-5-20250929")

def get_news_with_web_search(query="æœ€æ–°å›½é™…æ–°é—»"):
    """ä½¿ç”¨ web_search å·¥å…·è·å–æ–°é—»"""

    url = f"{API_BASE_URL}/v1/messages"

    # æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´
    headers = {
        "x-api-key": API_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Accept": "application/json",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Accept-Encoding": "gzip, deflate, br"  # å‘Šè¯‰æœåŠ¡å™¨æ”¯æŒ brotli
    }

    data = {
        "model": DEFAULT_MODEL,
        "max_tokens": 2048,
        "messages": [
            {
                "role": "user",
                "content": f"è¯·æœç´¢å¹¶æä¾›{query}ï¼ŒåŒ…æ‹¬ï¼š1) æ–°é—»æ ‡é¢˜ 2) ç®€è¦å†…å®¹ 3) æ¥æºã€‚ç”¨ä¸­æ–‡å›ç­”ã€‚"
            }
        ],
        "tools": [{
            "type": "web_search_20250305",
            "name": "web_search",
            "max_uses": 5
        }]
    }

    try:
        print("=" * 80)
        print(f"ä½¿ç”¨ Web Search å·¥å…·è·å–: {query}")
        print("=" * 80)

        # ç¡®ä¿ requests è‡ªåŠ¨å¤„ç†è§£å‹
        response = requests.post(
            url,
            headers=headers,
            json=data,
            timeout=90  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºéœ€è¦æœç´¢ç½‘ç»œ
        )

        print(f"çŠ¶æ€ç : {response.status_code}")

        if response.status_code == 200:
            print("âœ… è¯·æ±‚æˆåŠŸ")

            # å°è¯•è·å– JSON å†…å®¹
            try:
                # å¦‚æœå“åº”æ˜¯ brotli å‹ç¼©çš„ï¼Œrequests ä¼šè‡ªåŠ¨è§£å‹
                result = response.json()

                print(f"\nå“åº”ç±»å‹: {result.get('type', 'unknown')}")
                print(f"æ¨¡å‹: {result.get('model', 'unknown')}")

                # è§£æå†…å®¹
                if "content" in result:
                    has_web_search = False
                    text_content = []
                    search_results = []

                    for item in result["content"]:
                        item_type = item.get("type", "")

                        if item_type == "server_tool_use" or item_type == "tool_use":
                            # Web search è¢«è°ƒç”¨
                            has_web_search = True
                            print(f"\nğŸ” æ£€æµ‹åˆ° Web Search è°ƒç”¨")
                            print(f"   æŸ¥è¯¢: {item.get('input', {}).get('query', 'N/A')}")

                        elif item_type == "web_search_tool_result":
                            # Web search ç»“æœ
                            print(f"\nğŸ“Š æ”¶åˆ°æœç´¢ç»“æœ")
                            content = item.get("content", [])
                            for result_item in content:
                                if result_item.get("type") == "web_search_result":
                                    title = result_item.get("title", "")
                                    url_link = result_item.get("url", "")
                                    search_results.append({
                                        "title": title,
                                        "url": url_link
                                    })
                                    print(f"   - {title}")
                                    print(f"     {url_link}")

                        elif item_type == "text":
                            # AI ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
                            text_content.append(item.get("text", ""))

                    # æ˜¾ç¤º AI çš„æ€»ç»“
                    if text_content:
                        full_text = "\n".join(text_content)
                        print(f"\nğŸ“° AI æ€»ç»“:\n")
                        print(full_text)
                        print("\n" + "=" * 80)

                        # ä¿å­˜ç»“æœ
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        filename = f"news_websearch_{timestamp}.txt"

                        with open(filename, "w", encoding="utf-8") as f:
                            f.write(f"å›½é™…æ–°é—» (Web Search) - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                            f.write("=" * 80 + "\n\n")

                            if search_results:
                                f.write("æœç´¢ç»“æœæ¥æº:\n")
                                for i, sr in enumerate(search_results, 1):
                                    f.write(f"{i}. {sr['title']}\n")
                                    f.write(f"   {sr['url']}\n\n")
                                f.write("=" * 80 + "\n\n")

                            f.write(full_text)

                        print(f"\nâœ“ å·²ä¿å­˜åˆ° {filename}")

                        # åŒæ—¶ä¿å­˜ JSON
                        json_file = f"news_websearch_{timestamp}.json"
                        with open(json_file, "w", encoding="utf-8") as f:
                            json.dump(result, f, indent=2, ensure_ascii=False)
                        print(f"âœ“ å®Œæ•´å“åº”å·²ä¿å­˜åˆ° {json_file}")

                        return True
                    else:
                        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹")

                        # ä¿å­˜åŸå§‹å“åº”ç”¨äºè°ƒè¯•
                        with open("debug_response.json", "w", encoding="utf-8") as f:
                            json.dump(result, f, indent=2, ensure_ascii=False)
                        print("è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜åˆ° debug_response.json")

                else:
                    print("âŒ å“åº”ä¸­æ²¡æœ‰ content å­—æ®µ")

            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æå¤±è´¥: {e}")

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰‹åŠ¨è§£å‹ brotli
                try:
                    import brotli
                    decompressed = brotli.decompress(response.content)
                    result = json.loads(decompressed)
                    print("âœ“ ä½¿ç”¨ brotli æ‰‹åŠ¨è§£å‹æˆåŠŸ")

                    # å¤„ç†è§£å‹åçš„ç»“æœï¼ˆé‡å¤ä¸Šé¢çš„é€»è¾‘ï¼‰
                    with open("brotli_decompressed.json", "w", encoding="utf-8") as f:
                        json.dump(result, f, indent=2, ensure_ascii=False)
                    print("è§£å‹åçš„å†…å®¹å·²ä¿å­˜åˆ° brotli_decompressed.json")

                except ImportError:
                    print("âš ï¸  éœ€è¦å®‰è£… brotli: pip install brotli")
                except Exception as e2:
                    print(f"âŒ Brotli è§£å‹å¤±è´¥: {e2}")

        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯: {response.text[:500]}")

        return False

    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}")
        return False

if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("å›½é™…æ–°é—»è·å–å·¥å…· - ä½¿ç”¨ Web Search")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80 + "\n")

    # è·å–æœ€æ–°çš„å›½é™…æ–°é—»
    get_news_with_web_search("æœ€æ–°5æ¡é‡è¦å›½é™…æ–°é—»")

    print("\n" + "=" * 80)
    print("å®Œæˆ")
    print("=" * 80)